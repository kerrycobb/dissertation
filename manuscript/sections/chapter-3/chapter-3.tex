\section{Introduction}

Current model-based methods of species tree inference require biologists to
make difficult decisions about their genomic data.
They must decide whether to assume
(1) sites in their alignments are each inherited independently (``unlinked''),
or
(2) groups of sites are inherited together (``linked'').
If assuming the former, they must then decide whether to analyze all of their
data or only putatively unlinked variable sites.
Our goal in this chapter is to use simulated data to
help guide these choices by
comparing the robustness of different approaches to
errors that are likely common in high-throughput genetic
datasets.

Reduced-representation genomic data sets acquired from high-throughput
instruments are becoming commonplace in phylogenetics \parencite{leacheUtilitySingleNucleotide2017}, and
usually comprise hundreds to thousands of loci from 50 to several thousand
nucleotides long.
Full likelihood approaches
for inferring species trees from such datasets
can be
classified into two groups based on how they model the
evolution of orthologous DNA sites along gene trees within the species
tree---those that assume (1) each site evolved along its own gene tree
(i.e., each site is ``unlinked'')
\parencite{bryantInferringSpeciesTrees2012, maioPoMoAlleleFrequencyBased2015},
or (2) contiguous, linked sites evolved along a shared gene tree
\parencite{liuSpeciesTreesGene2007, heledBayesianInferenceSpecies2010, ogilvieStarBEAST2BringsFaster2017,
yangBPPProgramSpecies2015}.
We will refer to these as unlinked and linked-character models, respectively.
For both models, the gene tree of each
locus (whether each locus is a single site or a segment of linked sites)
is assumed to be independent of the gene
trees of all other loci, conditional on the species tree.
Methods using linked character models become computationally expensive as the
number of loci grows large, due to the estimation or numerical integration of
all of the gene trees
\parencite{yangBPPProgramSpecies2015,ogilvieStarBEAST2BringsFaster2017}.
Unlinked-character models on the other hand are more tractable for a large
number of loci, because  estimating individual gene trees is avoided by
analytically integrating over all possible gene trees
\parencite{bryantInferringSpeciesTrees2012, maioPoMoAlleleFrequencyBased2015}.
Whereas unlinked-character models can accommodate a larger number of loci than
linked-character models, most genetic data sets comprise linked sites and
unlinked-character models are unable to utilize the aggregate information about
ancestry contained in such linked sites.

Investigators are thus faced with decisions about how best to
use their data to infer a species tree.
Should they use a linked-character method that assumes the sites within each
locus evolved along a shared gene tree?
Ideally, the answer would be ``yes,'' however this is not always
computationally feasible and the model could be violated by intralocus
recombination.
Alternatively, should investigators remove all but one single-nucleotide
polymorphism (SNP) from each locus and use an unlinked-character model?
Or, perhaps they should apply the unlinked-character method to all of their
sites, even if this violates the assumption that each site evolved along an
independent gene tree.
Important considerations in such decisions include
the sources of error and bias that result from reduced-representation protocols,
high-throughput sequencing technologies, and the processing of these data.

Most reduced-representation sequencing workflows employ amplification of DNA
using polymerase chain reaction (PCR) which can introduce mutational error at a
rate of up to $1.5\times10^{-5}$ substitutions per base \parencite{potapovExaminingSourcesError2017}.
% Furthermore, amplification of different genome regions can be highly variable
% resulting in uneven coverage across loci
% \parencite{airdAnalyzingMinimizingPCR2011}.
Furthermore, current high-throughput sequencing technologies have non-negligible rates of error.
For example, Illumina sequencing platforms have been shown to have error rates
as high as 0.25\% per base \parencite{pfeifferSystematicEvaluationError2018}.
In hope of removing such errors, it is common for biologists to filter out
variants that are not found above some minimum frequency threshold
\parencite{rochetteStacksAnalyticalMethods2019, linckMinorAlleleFrequency2019}.
The effect of this filtering will be more pronounced in data sets with low or
highly variable coverage.
Also, to avoid aligning paralogous sequences,
it is common to remove loci
that exceed an upper threshold on the number of variable
sites \parencite{harveySimilarityThresholdsUsed2015}.
These processing steps can introduce errors and acquisition biases, which have
been shown to affect estimates derived from the assembled alignments
\parencite{harveySimilarityThresholdsUsed2015,huang2016unforeseen,linckMinorAlleleFrequency2019}.
Given these issues are likely common in high-throughput genomic data,
downstream decisions about what methods to use and what data to include in
analyses should consider how sensitive the results might be to
errors and biases introduced during data collection and processing.
% \kaccomment{Discuss biases inherent to reduced rep techniques?}
% Different library preparation techniques can introduce biases.
% Maybe mention this in general terms. Could be specific but maybe not necessary
% since none of our simulations were specifically intended to emulate these. 
% Effect of RADSeq: Allelic dropout due to mutations in restriction site
% \parencite{Rivera-Colon2019}

% Effect of Seq Cap: As sequence similarity decreases, DNA hybridization efficiency
% goes down.

% Effect of Transcriptome: 
% \parencite{freedmanErrorNoiseBias2019}


Our goal is to determine whether linked and unlinked character models
differ in their robustness to errors in reduced-representation genomic data,
and whether it is better to use all sites or only SNPs for unlinked character
methods.
Linked-character models can leverage shared information among linked sites
about each underlying gene tree.
Thus, these models might be able to correctly infer the general shape and depth
of a gene tree, even if the haplotypes at some of the tips have errors.
Unlinked character models have very little information about each gene tree,
and rely on the frequency of allele counts across many characters to inform the
model about the relative probabilities of all possible gene trees.
% (\jrocomment{Figure showing this difference?}).
Given this reliance on accurate allele count frequencies, we predict that
unlinked character models will be more sensitive to errors and acquisition
biases in genomic data.
To test this prediction that linked character models are more robust to the
types of errors contained in reduced-representation data,
we simulated data sets with varying degrees of errors related to miscalling
rare alleles and heterozygous sites.
Our results support this prediction, but also show that with only two species,
the region of parameter space where there are differences between linked and
unlinked character models is quite limited.
Further work is needed to determine whether this difference in robustness
between linked and unlinked character models will increase for larger species
trees.


\section{Methods}

\subsection{Simulations of error-free data sets}
For our simulations, we assumed a simple two-tipped species tree with one 
ancestral population with a constant effective size of \rootpopsize that 
diverged at time \divtime into two descendent populations (terminal branches) 
with constant effective sizes of \tippopsize[1] and \tippopsize[2] (\cref{fig:spTreeModel}).
For two diploid individuals sampled from each of the terminal
populations (4 sampled gene copies per population),
we simulated 100,000 orthologous biallelic characters under a finite-sites,
continuous-time Markov chain (CTMC) model of evolution.
We simulated 100 data sets comprised of loci of four different lengths---1000,
500, 250, and 1 characters.
We assume each locus is effectively unlinked and has no intra-locus
recombination; i.e., each locus evolved along a single gene tree that is
independent of the other loci, conditional on the species tree.
We chose this simple species tree model for our simulations to help ensure any
differences in estimation accuracy or precision were due to differences in the
underlying linked and unlinked character models,
and \emph{not} due to differences in numerical algorithms for searching species
and gene tree space.
Furthermore, we simulated biallelic characters, because unlinked-character
multi-species coalescent models
\parencite{bryantInferringSpeciesTrees2012,oaksFullBayesianComparative2019}
that are most comparable to linked-character models
\parencite{heledBayesianInferenceSpecies2010,ogilvieStarBEAST2BringsFaster2017}
are limited to characters with (at most) two states.

We simulated the two-tipped species trees under a pure-birth process
\parencite{Yule1925} with a birth rate of 10 using the \python package \dendropy
\parencite[Version 4.40, Commit eb69003;][]{sukumaranDendroPyPythonLibrary2010}.
This is equivalent to the time of divergence between the two species being
Exponentially distributed with a mean of 0.05 substitutions per site.
We drew population sizes for each branch of the species tree from a Gamma 
distribution with a shape of 5.0 and mean of 0.002.
We simulated 100, 200, 400, and 100,000 gene trees for data sets with loci of
length 1000, 500, 250, and 1, respectively, using the contained coalescent
implemented in \dendropy.
We simulated linked biallelic character alignments using
\seqgen (Version 1.3.4)
\parencite{rambautSeqGenApplicationMonte1997}
with a GTR model with base frequencies of A and C equal to 0 and base 
frequencies of G and T equal to 0.5.
The transition rate for all base changes was 0, except for the rate between G
and T which was 1.0. 

\subsection{Introducing Site-pattern Errors}
From each simulated dataset containing linked characters described above, we 
created four datasets by 
introducing two types of errors at two levels of frequency. The first type of 
error we introduced was changing singleton character patterns (i.e., characters 
for which one gene copy was different from the other seven gene copies) to invariant 
patterns by changing the singleton character state to match the other gene 
copies. We introduced this change to all singleton site patterns with a probability of 0.2 and 0.4 to create 
two datasets from each simulated dataset. The second type of error we introduced
was missing heterozygous gene copies. To do this, we randomly paired gene copies
from within each species to create two diploid genotypes for each locus, and with a probability
% Spelling out the pairing a bit more, but double check that "each genotype"
% below is accurate. I'm prettys sure it is based on the simulation code.
of 0.2 or 0.4 we randomly replaced one allele of each genotype with the other. For the unlinked character
dataset comprised of a single site per locus, we only simulated singleton 
character pattern error at a probability of 0.4.

\subsection{Assessing Sensitivity to Errors}
For each simulated data set with loci of 250, 500, and 1000 characters, we
approximated the posterior distribution of the 
divergence time (\divtime) and effective population sizes (\rootpopsize, \tippopsize[1], and \tippopsize[2])
under an unlinked-character model using \ecoevolity
\parencite[Version 0.3.2, Commit a7e9bf2;][]{oaksFullBayesianComparative2019}
and a linked-character model using the \beast package
\parencite[Version 0.15.1;][]{ogilvieStarBEAST2BringsFaster2017} in \beastcore
\parencite[Version 2.5.2;][]{bouckaertBEASTSoftwarePlatform2014}.
For both methods, we specified a CTMC model of character evolution and prior
distributions that matched the model and distributions from which the data were
generated. The prior on the effective size of the root population in the original
implementation of \ecoevolity was parameterized to be relative to the mean
effective size of the descendant populations.
We added an option to \ecoevolity to compile a version where the prior is
specified as the absolute effective size of the root population,
which matches the model in \beast and the model we used to generate the data.
The linkage of sites within loci of our simulated data violates the 
unlinked-character model of \ecoevolity \parencite{bryantInferringSpeciesTrees2012,oaksFullBayesianComparative2019}. Therefore, we also analyzed each data 
set with \ecoevolity after selecting, at most, one variable character from 
each locus; loci without variable sites were excluded. 

We analyzed the data sets simulated with 1-character per locus (i.e., unlinked
data) with \ecoevolity.
Our goal with these analyses was to
verify that the generative model of our simulation pipeline matched the
underlying model of \ecoevolity, and to confirm that any behavior of the method
with the other simulated data sets was not being caused by the linkage
violation.

For \ecoevolity, we ran four independent Markov chain Monte Carlo (MCMC)
analyses with 75,000 steps and a sample frequency of 50 steps.
For \beast, we ran two independent MCMC analyses with 20 million steps and a
sample frequency of 5000 steps. 
To assess convergence and mixing of the \ecoevolity and \beast MCMC chains, we
computed the effective sample size
\parencite[ESS;][]{Gong2014}
and potential scale reduction factor
\parencite[PSRF; the square root of Equation 1.1 in][]{Brooks1998}
from the samples of each parameter, and considered an ESS value greater than
200 and PSRF less than 1.2 \parencite{Brooks1998} to indicate adequate convergence
and mixing of the chains. 
Based on preliminary analyses of simulated data sets without errors,
we chose to discard the first 501 and 201 samples from
the MCMC chains of \ecoevolity and \beast, leaving 4000 and
7600 posterior samples for each data set, respectively.


\subsection{Project repository}
The full history of this project has been version-controlled and is available
at
\url{https://github.com/kerrycobb/align-error-sp-tree-sim},
and includes
all of the data and scripts necessary to produce our results.


\section{Results}

\subsection{Behavior of linked (\beast) versus unlinked (\ecoevolity) character
    models}
    
The divergence times estimated by the linked-character method, \beast, were very
accurate and precise for all alignment lengths and types and degrees
errors, despite poor MCMC mixing (i.e., low ESS values) for shorter loci
\timefigsp. 
For data sets without error, the unlinked-character method, \ecoevolity,
estimated divergence times with similar accuracy and precision as \beast when
all characters are analyzed \timefigsp.
However when alignments contained errors, \ecoevolity underestimated very
recent divergence times with increasing severity as the frequency of errors
increased \timefigsp; estimates of older divergence times were unaffected.

The biased underestimation of divergence times by \ecoevolity in the face of
errors was coupled with overestimation of the ancestral effective population
sizes (\cref{fig:roottheta1000,fig:roottheta500,fig:roottheta250}).
When analyzing the alignments without errors, \ecoevolity essentially returned
the prior distribution on the effective size of the ancestral population
(\cref{fig:roottheta1000,fig:roottheta500,fig:roottheta250}).
Despite poor MCMC mixing,
\beast consistently estimated the effective size of
the ancestral population better than \ecoevolity and was unaffected by errors
in the data
(\cref{fig:roottheta1000,fig:roottheta500,fig:roottheta250}),
and the precision of \beast{}'s estimates of \rootpopsize increased with locus
length.

Estimates of the effective size of the descendant populations
are largely similar between \beast and \ecoevolity;
both methods underestimate the descendant population sizes when
the data sets contain errors, and this downward bias is generally
worse for \ecoevolity
(\cref{fig:theta1000,fig:theta500,fig:theta250}).
The degree of underestimation increases with the rate of errors in the data
sets for both \beast and \ecoevolity, and the results were largely consistent
across different locus lengths.
(\cref{fig:theta1000,fig:theta500,fig:theta250}).

When we apply \ecoevolity to data sets simulated with unlinked characters
(i.e., data sets simulated with 1-character per locus),
we see the same patterns of biased parameter estimates
in response to errors
(\cref{fig:ecoevolityunlinked})
as we did with the linked loci \timefigsp.
These results rule out the possibility that the greater sensitivity of
\ecoevolity to the errors we simulated is due to violation of the method's
assumption that all characters are unlinked.

\subsection{Analyzing all sites versus SNPs with \ecoevolity}

The unlinked character model implemented in \ecoevolity assumes that orthologous 
nucleotide sites evolve independently along separate gene trees. The data however, were
simulated under a model assuming that contiguous linked sites evolve along a shared 
gene tree. It would thus be a violation of the \ecoevolity model to include all
sites in the analysis.
However, avoiding this violation by removing all but one variable site per
locus drastically reduces the amount of data.
When analyzing the simulated data sets without errors, the precision and accuracy of
parameter estimates by \ecoevolity was much greater
when all sites of the alignment were used relative to when a single SNP per 
locus was used despite violating the model \mainfigsp.
This was generally true across the different lengths of loci, however, the
coverage of credible intervals is lower with longer loci.
Analyzing only SNPs does make \ecoevolity more robust to the errors
we introduced.
However, this robustness is due to the lack of information in the
SNP data leading to wide credible intervals, and in the case of
population size parameters, the marginal posteriors essentially
match the prior distribution \thetafigsp.

% Put this in the discussion somewhere
% The results from this analysis were consistent
% with \parencite{oaksFullBayesianComparative2019} 




\subsection{Coverage of credible intervals}
The 95\% credible intervals for divergence times and effective population sizes
estimated from alignments without error in \beast had the expected coverage
frequency in that the true value was within approximately 95\% of the estimated
credible intervals. 
This was also true for \ecoevolity when analyzing data sets simulated with
unlinked characters (i.e., no linked sites).
%\cref{fig:ecoevolityunlinked}.
This coverage behavior is expected, and helps to confirm confirm that our
simulation pipeline generated data under the same model used for inference by
\beast and \ecoevolity. 
As seen previously \parencite{oaksFullBayesianComparative2019}, analyzing longer linked loci
causes the coverage of \ecoevolity to be lower, due to the violation of the
model's assumption that the sites are unlinked.

\subsection{MCMC convergence and mixing}
Most sets of \beast and \ecoevolity MCMC chains yielded samples of parameters with
a PSRF less than 1.2, indicative of convergence.
However, we do see poor mixing (ESS < 200) of the \beast chains as the length
of loci decreases (\mainfigs;
yellow indicates ESS < 200, red indicates PSRF > 1.2, green indicates both)
We only see evidence of poor mixing and convergence for \ecoevolity when
applied to data sets with errors.
This is in contrast to \beast, for which the frequency and degree of poor MCMC
behavior is largely unaffected by the type or frequency of errors.
The proportion of simulation replicates where \beast had an ESS of the
ancestral population size less than 200 was high across all analyses
\rootfigsp.
For the descendant population size, \beast had better ESS values across all
analyses, with the exception of rare estimates of essentially zero when
analyzing 250 bp loci \thetafigsp.


\section{Discussion}

Phylogeneticists seeking to infer species trees from large, multi-locus data
sets are faced with difficult decisions regarding assumptions about linkage
across sites and, if assuming all sites are unlinked, what data to include in
their analysis.
With the caveat that we only explored trees with two species,
the results of our simulations provide some guidance for these decisions. 
As we predicted, the linked-character method we tested, \beast, was more robust
to the sequencing errors we simulated than the unlinked character method,
\ecoevolity.
However, even with only two species in our simulations, the current
computational limitations of linked-character models was apparent from the poor
sampling efficiency of the MCMC chains, especially with shorter loci.
For data sets with more species and many short loci, linked character models
are theoretically appealing, but current implementations may not be
computationally feasible.
The unlinked character method, \ecoevolity, was more sensitive to sequence
errors, but was still quite robust to realistic levels of errors and is more
computationally feasible thanks to the analytical integration over gene trees.

Overall, for data sets with relatively long loci, as is common with
sequence-capture approaches, it might be worth trying a linked-character
method.
If computationally practical, you stand to benefit from the aggregate
information about each gene tree contained in the linked sites of each locus.
However, if your loci are shorter, as in restriction-site-associated DNA (RAD)
markers, you are likely better off applying an unlinked-character model to all
of your data, even though this violates an assumption of the model.
Below we discuss why performance differs between methods, locus lengths, and
degree of error in the data, and what this means for the analyses of empirical
data. 

\subsection{Robustness to character-pattern errors}
As predicted, the linked-character model of \beast was more robust to erroneous
character patterns in the alignments than the unlinked-character model of
\ecoevolity.
This is most evident in the estimates of divergence times, for which
the two methods perform very similarly when there are no errors in the
data (Row 1 of \timefigs).
When errors are introduced, the divergence time estimates of \beast are
unaffected, but \ecoevolity underestimates recent divergence times as both
singleton and heterozygosity errors become more frequent (Rows 2--5 of
\timefigs).
However, \ecoevolity divergence-time estimates are only biased at
very recent divergence times, and the effect disappears
when the time of divergence is larger than about $8N_e\mu$.

These patterns make sense given that both types of errors we simulated
reduce variation \emph{within} each species.
Thus, it is not too surprising that the unlinked-character model in \ecoevolity
struggles when there is shared variation between
the two populations (i.e., most gene trees have more than
two lineages that coalesce in the ancestral population).
The erroneous character patterns mislead both models that the effective size of
the descendant branches is smaller than they really are
(\cref{fig:theta1000,fig:theta500,fig:theta250}).
To explain the shared variation between the species (i.e. deep coalescences)
when underestimating the descendant population sizes,
the unlinked-character model of \ecoevolity
simultaneously reduces the divergence time and increases the effective
size of the ancestral population.
Despite also being misled about the size of the descendant populations
(\cref{fig:theta1000,fig:theta500,fig:theta250}),
the linked-character model of \beast seems to benefit from more information
about the general shape of each gene tree across the linked sites and can still
maintain an accurate estimate of the divergence time
\timefigsp
and ancestral population size
(\cref{fig:roottheta1000,fig:roottheta500,fig:roottheta250}).

This downward biased variation within each species becomes
less of a problem for the unlinked-character model as the
divergence time gets larger, likely because the average gene
tree only has a single lineage from each species that coalesces
in the ancestral population.
As the coalesced lineage within each species leading back to the ancestral
population becomes a large proportion of the overall length of the average gene
tree, the proportion of characters that either show fixed differences between
the species or are invariant likely provides enough information to the unlinked
character model about the time of divergence to overcome the downward biased
estimates of the descendant population sizes.

From the \ecoevolity results,
we also see that when faced with heterozygosity errors,
accuracy decreases as locus length increases.
In contrast, accuracy of \ecoevolity is not affected by locus
length when analyzing data sets with singleton errors.
This pattern makes sense in light of how we generated these errors.
We introduced singleton errors per-site and heterozygosity errors per-locus.
Thus, the same per-locus rate of heterozygosity errors affects many more sites
of a dataset with 1000bp loci compared to dataset with 250bp loci.

Unsurprisingly, the MCMC sampling performance of \beast declines with
decreasing locus length.
There is less information in the shorter loci about ancestry, and thus more
posterior uncertainty about the gene trees.
This forces \beast to traverse a much broader distribution of gene trees during
MCMC sampling, which is difficult due to the constraints imposed by the
species tree.
This decline in MCMC performance in \beast does not appear to correlate with
poor parameter estimates and the distribution of estimates is generally as good
or better than those from \ecoevolity. 
However, this might be due to fact that there is no uncertainty in the species
tree in any of our analyses, because there are only two species.
As the number of species increases, it seems likely that the MCMC performance
will further decline and start to affect parameter and topology estimates.


\subsection{Relevance to empirical data sets}
% Application
It is reassuring to see the effect of sequence errors on the unlinked-character
model is limited to a small region of parameter space, and is only severe when
the frequency of errors in the data is large.
Our simulated error rate of 40\% is likely higher than the rate that these
types of errors occur during most sample preparation, high-throughput sequencing,
and bioinformatic processing.
However, empirical alignments likely contain a mix of different sources of
errors and biases from various steps in the data collection process.
Also, real data are not be generated under a known model with no prior
misspecification.
Violations of the model might make these methods of species-tree inference more
sensitive to lower rates of error.

The degree to which a dataset will be affected by errors from missing
heterozygote haplotypes and missing singletons will be highly dependent on the 
method used to reduce representation of the genome, depth of sequencing 
coverage (i.e., the number of overlapping sequence reads at
a locus), and how the data are processed.
To filter out sequencing errors, most pipelines for processing sequence reads
set a minimum coverage threshold for variants or a minimum minor allele
frequency.
This can result in the miscalling or removal of true variation, especially
if coverage is low due to random chance or biases in PCR amplification and
sequencing.
Processing the data in this way can result in biased estimates of parameters
that are sensitive to the frequencies of rare alleles
\parencite{huang2016unforeseen,linckMinorAlleleFrequency2019}.
If the thresholds for such processing steps are stringent, it could introduce
levels of error greater than our simulations.

% There is one potential source of error which would have a greater 
% affect than the error we simulated. Filtering of rare alleles that do not meet 
% a minimum minor allele frequency or count threshold in order to remove potential 
% sequencing errors eliminates every allele below that threshold rather than a 
% proportion as in our simulations 
% \parencite{rochetteStacksAnalyticalMethods2019, linckMinorAlleleFrequency2019}.



\subsection{Recommendations for using unlinked-character models}

When erroneous character patterns cause \ecoevolity to underestimate the
divergence time it also inflates the effective population size of the ancestral
population.
We are seeing values of $\rootpopsize\mu$ consistent with an average sequence
divergence between individuals \emph{within} the ancestral population of 3\%,
which is almost an order of magnitude larger than our prior mean expectation
(0.4\%).
Thus, looking for unrealistically large population sizes estimated for internal
branches of the phylogeny might provide an indication that the
unlinked-character model is not explaining the data well.
However, there is little information in the data about the effective population
sizes along ancestral branches,
so the parameter that might indicate a problem is going to have very
large credible intervals.
Nonetheless, many of the posterior estimates of the ancestral population size
from our data sets simulated with character-pattern errors are well beyond the
prior distribution.

Whether using linked or unlinked-character models with empirical
high-throughput data sets, it is good practice to perform analyses on
different versions of the aligned data that are assembled under different
coverage thresholds for variants or alleles.
Variation of estimates derived from different assemblies of the data might
indicate that the model is sensitive to the errors or acquisition biases in the
alignments.
This is especially true for data where sequence coverage is low for samples
and/or loci.
Given our findings, it might be helpful to compare the estimates of the
effective population sizes along internal branches of the tree.
Seeing unrealistically large estimates for some assemblies of the
data might indicate that the model is being biased by
errors or acquisition biases present in the character patterns.

Consistent with what has been shown in previous work
\parencite{oaksFullBayesianComparative2019,oaks2019comparative},
\ecoevolity performed better when all sites were utilized despite violating the
assumption that all sites are unlinked.
This suggests that investigators might obtain better estimates by analyzing all
their data under unlinked-character models, rather than discarding much of it
to avoid violating an assumption of the model.
Given that the model of unlinked characters implemented in \ecoevolity
does not use information about linkage among sites 
\parencite{bryantInferringSpeciesTrees2012, oaksFullBayesianComparative2019},
it is not surprising that this model violation does not introduce a bias.
Linkage among sites does not change the gene trees and site patterns that are
expected under the model, but it does reduce the variance of the those patterns
due to them evolving along fewer gene trees.
As a result, the accuracy of the parameter estimates is not affected
by the linkage among sites within loci, but the credible intervals
become too narrow as the length of loci increase
\parencite{oaksFullBayesianComparative2019,oaks2019comparative}.
However, it remains to be seen whether the robustness of the model's accuracy
to linked sites holds true for larger species trees.


\subsection{Other complexities of empirical data in need of exploration}
% Larger trees
Our goal was to compare the theoretical performance of linked and unlinked
character models, not their current software implementations.
Accordingly, to minimize differences in performance that are due to differences
in algorithms for exploring the space of gene and species trees, we restricted
our simulations to two species model and a small number of individuals.
Nonetheless, exploring how character-pattern errors and biases affect
the inference of larger species trees would be informative.
The species tree topology is usually a parameter of great interest to
biologists, so it would be interesting to know whether 
the linked model continues to be more robust to errors than the unlinked 
model as the number of species increases.
We saw the MCMC performance of \beast decline concomitantly with locus length
in our simulations due to greater uncertainty in gene trees.
Given that data sets frequently contain loci shorter than 250 bp, it is
important to know whether good sampling of the posterior of linked-character
models becomes prohibitive for larger trees.
Also, \ecoevolity greatly overestimated the effective size of the ancestral
population in the face of high rates of errors in the data.
Exploring larger trees will also determine whether this behavior is limited to
the root population or is a potential problem for all internal branches of the
specie tree.

% Similarity Thresholds
Exploring other types of errors and biases would also be informative.
To generate alignments of orthologous loci from high-throughput data, 
sequences are matched to a similar portion of a reference sequence or 
clustered together based on similarity. To avoid aligning paralogous sequences 
it is necessary to establish a minimum level of similarity for establishing 
orthology between sequences. This can lead to an acquisition bias due to the 
exclusion of more variable loci or alleles from the alignment \parencite{huang2016unforeseen}.
Furthermore, when a reference 
sequence is used, this data filtering will not be random with respect to the
species, but rather there will be a bias towards filtering loci and alleles
with greater sequence divergence from the reference. 
Simulations exploring the affect of these types of data acquisition biases
would complement the errors we explored here.

% Diffuse Prior
In our analyses, there was no model misspecification other than the introduced
errors (except for the linked sites violating the unlinked-character model).
With empirical data, there are likely many model violations,
and our prior distributions will never match the distributions that generated
the data.
Introducing other model violations and misspecified prior distributions
would thus help to better understand how species-tree models behave on real
data sets.
Of particular concern is whether misspecified priors will amplify the effect of
character-pattern errors or biases.

We found that character-pattern errors that remove variation from within
species can cause unlinked-character models to underestimate divergence
times and overestimate ancestral population sizes in order to explain shared
variation among species.
This raises the question of whether we can explicitly model and correct for
these types of data collection errors in order to avoid biased parameter
estimates.
An approach that could integrate over uncertainty in the frequency of these
types of missing-allele errors would be particularly appealing.

% Low coverage from many individuals
% Our sample size of 4 gene copies per species is quite small. In order to gain high confidence
% in the genotypes of a small sample it is necessary to sequence each sample at 
% high coverage. However there is a high probability that the counts of of alleles 
% in a small sample size are very low and therefore difficult to distinguish from
% mutational or basecalling error. One proposed approach to better detect polymorphisms 
% within populations is to sequence a large number of individuals at low coverage
% (~2x) \parencite{buerklePopulationGenomicsBased2013}.

% Our results raise interesting questions that can be further explored\ldots
% \begin{itemize}
    % \item Larger trees. Will non-root internal branches suffer from bias, or
    %     only the root? Will only branches ancestral to short branches suffer?
    %     Will linked-site models remain robust?
    %     Will biased div times and pop sizes also affect accuracy of topology
    %     estimates?
    % \item Acquisition biases. E.g., removing most variable loci to avoid
    %     paralogy. Will this only have an affect at recent times? Or will
    %     this affect be more pervasive across parameter space?
    %     Will linked-site models remain robust
    % \item What erroneous site patterns have the largest affect on
    %     the likelihood? Can we model and correct for these?
    % \item Are larger population sample sizes more robust? Perhaps it is better
        % to sequence a larger number of individuals at lower coverage 
        % \parencite{fumagalliAssessingEffectSequencing2013}.
    % \item We essentially had no model misspecification.
        % what happens when our priors are wrong/diffuse?
        % Will this amplify affect of errors/biases?
% \end{itemize}
